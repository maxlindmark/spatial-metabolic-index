---
title: "Collate CPUE data"
author: "Max Lindmark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  html:
    embed-resources: true
    fig-width: 8
    fig-asp: 0.618
knitr: 
  opts_chunk:
    fig.align: center
editor: source
execute: 
  echo: true
  eval: true
  cache: false
---

# Intro
In this script, I load exchange data from datras and calculate catch of cod and flounder in unit $\text{kg/km}^2$ (with TVL gear) by size group, by correcting for gear dimensions, sweeplength and trawl speed, following Orio et al 2017. 

## Load libraries

```{r setup}
#| warning: false
#| message: false

# Load libraries, install if needed
pkgs <- c("tidyverse", "readxl", "tidylog", "RCurl", "devtools", "patchwork",
          "janitor", "viridis", "RColorBrewer", "icesDatras", "mapdata", "rgdal",
          "raster", "sf", "rgeos", "chron", "lattice", "ncdf4", "marmap", "rnaturalearth",
          "rnaturalearthdata", "mapplots", "geosphere", "modelr") 

if(length(setdiff(pkgs,rownames(installed.packages()))) > 0){

    install.packages(setdiff(pkgs, rownames(installed.packages())), dependencies = T)
  
  }

invisible(lapply(pkgs, library, character.only = T))

# Packages not on CRAN or dec version
# remotes::install_github("pbs-assess/sdmTMB", dependencies = TRUE)
# devtools::install_github("seananderson/ggsidekick") # not on CRAN 
library(sdmTMB)
library(ggsidekick)
theme_set(theme_sleek())

world <- ne_countries(scale = "medium", returnclass = "sf")

# Set path
home <- here::here()
```

## Read data

```{r read data}
#| message: false

# Data were read in from getDATRAS on 2022.09.06
# Read HH data
#bits_hh <- getDATRAS(record = "HH", survey = "BITS", years = 1991:2021, quarters = c(1, 4))
#write_csv(bits_hh, paste0(home, "/data/DATRAS_exchange/bits_hh.csv"))
bits_hh <- read_csv(paste0(home, "/data/DATRAS_exchange/bits_hh.csv")) |> filter(Year > 1992) # To match covariates

# Read HL data
#bits_hl <- getDATRAS(record = "HL", survey = "BITS", years = 1991:2021, quarters = c(1, 4))
#write_csv(bits_hl, paste0(home, "/data/DATRAS_exchange/bits_hl.csv"))
bits_hl <- read_csv(paste0(home, "/data/DATRAS_exchange/bits_hl.csv")) |> filter(Year > 1992) # To match covariates

# Read CA data
#bits_ca <- getDATRAS(record = "CA", survey = "BITS", years = 1991:2021, quarters = c(1, 4))
#write_csv(bits_ca, paste0(home, "/data/DATRAS_exchange/bits_ca.csv"))
bits_ca <- read_csv(paste0(home, "/data/DATRAS_exchange/bits_ca.csv")) |> filter(Year > 1992) # To match covariates

# Read gear standardization data 
sweep <- read.csv(paste0(home, "/data/gear_standardization/sweep_9116.csv"), sep = ";", dec = ",", fileEncoding = "latin1")
sweep <- read.csv(paste0(home, "/data/gear_standardization/sweep_9118_ml.csv"), sep = ";", fileEncoding = "latin1")
```

## Standardize catch data
#### Standardize ships

```{r ships}
#| message: false

# Before creating a a new ID, make sure that countries and ships names use the same format
sort(unique(sweep$Ship))
sort(unique(bits_hh$Ship))
sort(unique(bits_hl$Ship))

# Change back to the old Ship name standard...
# https://vocab.ices.dk/?ref=315
# https://vocab.ices.dk/?ref=315
# Assumptions:
# SOL is Solea on ICES links above, and SOL1 is the older one of the two SOLs (1 and 2)
# DAN is Dana
# sweep |> filter(Ship == "DANS") |> distinct(Year, Country)
# sweep |> filter(Ship == "DAN2") |> distinct(Year)
# bits_hh |> filter(Ship == "67BC") |> distinct(Year, Country)
# sweep |> filter(Ship == "DAN2") |> distinct(Year)
# bits_hh |> filter(Ship == "26D4") |> distinct(Year) # Strange that 26DF doesn't extend far back. Which ship did the Danes use? Ok, I have no Danish data that old.
# bits_hh |> filter(Country == "DK") |> distinct(Year)

bits_hh <- bits_hh |>
  mutate(Ship2 = fct_recode(Ship,
                            "SOL" = "06S1", 
                            "SOL2" = "06SL",
                            "DAN2" = "26D4",
                            "HAF" = "26HF",
                            "HAF" = "26HI",
                            "HAF" = "67BC",
                            "BAL" = "67BC",
                            "ARG" = "77AR",
                            "77SE" = "77SE",
                            "AA36" = "AA36",
                            "KOOT" = "ESLF",
                            "KOH" = "ESTM",
                            "DAR" = "LTDA",
                            "ATLD" = "RUJB",
                            "ATL" = "RUNT"), 
         Ship2 = as.character(Ship2)) |> 
  mutate(Ship3 = ifelse(Country == "LV" & Ship2 == "BAL", "BALL", Ship2))

bits_hl <- bits_hl |>
  mutate(Ship2 = fct_recode(Ship,
                            "SOL" = "06S1", 
                            "SOL2" = "06SL",
                            "DAN2" = "26D4",
                            "HAF" = "26HF",
                            "HAF" = "26HI",
                            "HAF" = "67BC",
                            "BAL" = "67BC",
                            "ARG" = "77AR",
                            "77SE" = "77SE",
                            "AA36" = "AA36",
                            "KOOT" = "ESLF",
                            "KOH" = "ESTM",
                            "DAR" = "LTDA",
                            "ATLD" = "RUJB",
                            "ATL" = "RUNT"), 
         Ship2 = as.character(Ship2)) |> 
  mutate(Ship3 = ifelse(Country == "LV" & Ship2 == "BAL", "BALL", Ship2))

bits_ca <- bits_ca |>
  mutate(Ship2 = fct_recode(Ship,
                            "SOL" = "06S1", 
                            "SOL2" = "06SL",
                            "DAN2" = "26D4",
                            "HAF" = "26HF",
                            "HAF" = "26HI",
                            "HAF" = "67BC",
                            "BAL" = "67BC",
                            "ARG" = "77AR",
                            "77SE" = "77SE",
                            "AA36" = "AA36",
                            "KOOT" = "ESLF",
                            "KOH" = "ESTM",
                            "DAR" = "LTDA",
                            "ATLD" = "RUJB",
                            "ATL" = "RUNT"), 
         Ship2 = as.character(Ship2)) |> 
  mutate(Ship3 = ifelse(Country == "LV" & Ship2 == "BAL", "BALL", Ship2))

# Ok, which ships are missing in the exchange data?
unique(bits_hh$Ship3)[!unique(bits_hh$Ship3) %in% unique(sweep$Ship)]
# Swedish Ships and unidentified ships are NOT in the Sweep data
unique(sweep$Ship3)[!unique(sweep$Ship3) %in% unique(bits_hh$Ship3)]
# But all Sweep Ships are in the exchange data
```

#### Standardize countries

```{r countries}
#| message: false

# Now check which country codes are used
sort(unique(sweep$Country))
sort(unique(bits_hh$Country))

# https://www.nationsonline.org/oneworld/country_code_list.htm#E
bits_hh <- bits_hh |>
  mutate(Country = fct_recode(Country,
                              "DEN" = "DK",
                              "EST" = "EE",
                              "GFR" = "DE",
                              "LAT" = "LV",
                              "LTU" = "LT",
                              "POL" = "PL",
                              "RUS" = "RU",
                              "SWE" = "SE"),
         Country = as.character(Country))

bits_hl <- bits_hl |>
  mutate(Country = fct_recode(Country,
                              "DEN" = "DK",
                              "EST" = "EE",
                              "GFR" = "DE",
                              "LAT" = "LV",
                              "LTU" = "LT",
                              "POL" = "PL",
                              "RUS" = "RU",
                              "SWE" = "SE"),
         Country = as.character(Country))

bits_ca <- bits_ca |>
  mutate(Country = fct_recode(Country,
                              "DEN" = "DK",
                              "EST" = "EE",
                              "GFR" = "DE",
                              "LAT" = "LV",
                              "LTU" = "LT",
                              "POL" = "PL",
                              "RUS" = "RU",
                              "SWE" = "SE"),
         Country = as.character(Country))

# Gear? Are they the same?
sort(unique(bits_hh$Gear))
sort(unique(bits_hl$Gear))
sort(unique(sweep$Gear))

# Which gears are NOT in the sweep data?
unique(bits_hl$Gear)[!unique(bits_hl$Gear) %in% unique(sweep$Gear)] 
```

#### Create a simple haul ID that works across all exchange data

```{r haul id}
#| message: false

# Create ID column
bits_ca <- bits_ca |> 
  mutate(IDx = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

bits_hl <- bits_hl |> 
  mutate(IDx = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

bits_hh <- bits_hh |> 
  mutate(IDx = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

# Works like a haul-id
bits_hh |> group_by(IDx) |> mutate(n = n()) |> ungroup() |> distinct(n)
```

#### Create the same unique haul-ID in the cpue data that I have in the sweep-file

```{r haul id check}
#| message: false

bits_hl <- bits_hl |> 
  mutate(haul.id = paste(Year, Quarter, Country, Ship3, Gear, StNo, HaulNo, sep = ":")) 

bits_hh <- bits_hh |> 
  mutate(haul.id = paste(Year, Quarter, Country, Ship3, Gear, StNo, HaulNo, sep = ":")) 

bits_hh |> group_by(haul.id) |> mutate(n = n()) |> ungroup() |> distinct(n)
```

#### Clean DATRAS EXCHANGE data

```{r filter hauls}
#| message: false

# Select just valid, additional and no oxygen hauls
bits_hh <- bits_hh |>
  #filter(!Country == "SWE") |> # I'll deal with Sweden later...
  filter(HaulVal %in% c("A", "N", "V"))

# Add ICES rectangle
bits_hh$Rect <- mapplots::ices.rect2(lon = bits_hh$ShootLong, lat = bits_hh$ShootLat)

# Add ICES subdivisions
shape <- shapefile(paste0(home, "/data/ICES_StatRec_mapto_ICES_Areas/StatRec_map_Areas_Full_20170124.shp"))

pts <- SpatialPoints(cbind(bits_hh$ShootLong, bits_hh$ShootLat), 
                     proj4string = CRS(proj4string(shape)))

bits_hh$sub_div <- over(pts, shape)$Area_27

# Rename subdivisions to the more common names and do some more filtering (by sub div and area)
sort(unique(bits_hh$sub_div))

bits_hh <- bits_hh |> 
  mutate(sub_div = factor(sub_div),
         sub_div = fct_recode(sub_div,
                              "20" = "3.a.20",
                              "21" = "3.a.21",
                              "22" = "3.c.22",
                              "23" = "3.b.23",
                              "24" = "3.d.24",
                              "25" = "3.d.25",
                              "26" = "3.d.26",
                              "27" = "3.d.27",
                              "28" = "3.d.28.1",
                              "28" = "3.d.28.2",
                              "29" = "3.d.29"),
         sub_div = as.character(sub_div)) 

# Now add the fishing line information from the sweep file (we need that later
# to standardize based on gear geometry). We add in the the HH data and then
# transfer it to the other exchange data files when left_joining.
# Check which Fishing lines I have in the sweep data:
fishing_line <- sweep |> group_by(Gear) |> distinct(Fishing.line)

bits_hh <- left_join(bits_hh, fishing_line)
# sweep |> group_by(Gear) |> distinct(Fishing.line)
# bits_hh |> group_by(Gear) |> distinct(Fishing.line)
bits_hh$Fishing.line <- as.numeric(bits_hh$Fishing.line)

# Which gears do now have fishing line?
bits_hh$Fishing.line[is.na(bits_hh$Fishing.line)] <- -9
bits_hh |> filter(Fishing.line == -9) |> distinct(Gear)
# 1  GRT
# 2  CAM
# 3  EXP
# 4  FOT
# 5  GOV
# 6  EGY
# 7   DT
# 8  ESB
# 9  HAK

# FROM the index files (Orio, "Research Östersjön 2")
# FOT has 83
# GOV has 160
# ESB ??
# GRT ??
# Rest are unknown and likely not used by Swedish data (therefore their correction
# factors my be in the sweep file)

# Add these values:
bits_hh <- bits_hh |> mutate(Fishing.line = ifelse(Gear == "FOT", 83, Fishing.line))
bits_hh <- bits_hh |> mutate(Fishing.line = ifelse(Gear == "GOV", 160, Fishing.line))

# Now select the hauls in the HH data when subsetting the HL data
bits_hl <- bits_hl |>
  filter(haul.id %in% bits_hh$haul.id)

# Match columns from the HH data to the HL and CA data
sort(unique(bits_hh$sub_div))
sort(colnames(bits_hh))

# No NAs for the variables going in to the stomach haul ID
unique(is.na(bits_hh |> dplyr::select(Year, Quarter, Month, Country, Rect, HaulNo)))

unique(bits_hh$Country)

# MAKE SURE THE COUNTRY CODE IS THE SAME! FOR NOW I DON*T USE COUNTRY 2
bits_hh <- bits_hh |> mutate(Country2 = NA,
                              Country2 = ifelse(Country == "LAT", "LV", Country2),
                              Country2 = ifelse(Country == "POL", "PL", Country2),
                              Country2 = ifelse(Country == "SWE", "SE", Country2),
                              Country2 = ifelse(Country == "DEN", "DK", Country2))

bits_hh_merge <- bits_hh |> 
  mutate(id_haul_stomach = paste(Year, Quarter, Month, Country, Rect, HaulNo, sep = ".")) |> 
  dplyr::select(sub_div, Rect, HaulVal, StdSpecRecCode, BySpecRecCode, Fishing.line, Month,
                DataType, HaulDur, GroundSpeed, haul.id, IDx, ShootLat, ShootLong,
                id_haul_stomach, Depth) |> 
  rename(depth_obs = Depth)

bits_hl <- left_join(dplyr::select(bits_hl, -haul.id), bits_hh_merge, by = "IDx")
bits_ca <- left_join(bits_ca, bits_hh_merge, by = "IDx")

# Now filter the subdivisions I want from all data sets
bits_hh <- bits_hh |> filter(sub_div %in% c(24, 25, 26, 27, 28))
bits_hl <- bits_hl |> filter(sub_div %in% c(24, 25, 26, 27, 28))
bits_ca <- bits_ca |> filter(sub_div %in% c(24, 25, 26, 27, 28))
```

```{r test}
bits_hl |> filter(Year == 2016 & Quarter == 1 & Month == 2 & Country == "SWE" & Rect == "39G4") |> distinct(HaulNo)
```

#### Filter species

```{r filter species}
bits_hl |> 
  #filter(SpecCodeType == "W") |> 
  group_by(haul.id, SpecCode) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  group_by(SpecCode) |> 
  summarise(n = sum(n)) |> 
  filter(n > 2000) |> 
  mutate(species = SpecCode,
         species = ifelse(SpecCode %in% c("126417", "161722"), "herring", species),
         species = ifelse(SpecCode %in% c("126425", "161789"), "sprat", species),
         species = ifelse(SpecCode %in% c("126438", "164758"), "whiting", species),
         species = ifelse(SpecCode %in% c("126450", "164748"), "fourbeard_rockling", species),
         species = ifelse(SpecCode %in% c("126736"), "smelt", species),
         species = ifelse(SpecCode %in% c("127123"), "eelpout", species),
         species = ifelse(SpecCode %in% c("127139", "172881"), "dab", species),
         species = ifelse(SpecCode %in% c("127143", "172902"), "plaice", species),
         species = ifelse(SpecCode %in% c("127141", "172894"), "flounder", species),
         species = ifelse(SpecCode %in% c("127149", "616195"), "turbot", species),
         species = ifelse(SpecCode %in% c("127203"), "shorthorn_sculpin", species),
         species = ifelse(SpecCode %in% c("126436", "164712"), "cod", species)
         ) |> 
  ggplot() +
  geom_bar(aes(reorder(species, desc(n)), n), stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90, size = 11)) + 
  labs(x = "")

# Based on this plot, and species we have metabolic index parameters for, we will go ahead with the following species:
# Cod, flounder, plaice, dab

# Plot some species in space!
bits_hl |> 
  mutate(species = NA,
         species = ifelse(SpecCode %in% c("126436", "164712"), "cod", species),
         species = ifelse(SpecCode %in% c("127141", "172894"), "flounder", species),
         species = ifelse(SpecCode %in% c("127143", "172902"), "plaice", species),
         species = ifelse(SpecCode %in% c("127139", "172881"), "dab", species)) |> 
  drop_na(species) |> 
  group_by(Year, haul.id, ShootLong, ShootLat, species) |> 
  summarise(tot_no = sum(TotalNo)) |> 
  filter(tot_no > 0) |> 
  filter(ShootLong > 13.5) |> 
  ggplot(aes(ShootLong, ShootLat, color = log(tot_no))) + 
  geom_point() +
  facet_grid(species ~ Year)

t <- bits_ca |>
  filter(SpecCode %in% c("126436", "164712")) |>
  group_by(Year) |>
  drop_na(Age) |>
  summarise(max_age = max(Age, na.rm = TRUE))

t |> filter(Year %in% c(1995, 2019))

ggplot(t, aes(Year, max_age)) +
  geom_line()

# bits_ca |> 
#   filter(SpecCode %in% c("126436", "164712")) |> 
#   group_by(Year) |> 
#   drop_na(Age) |> 
#   # summarise(max_age = max(Age, na.rm = TRUE),
#   #           upr_age = quantile(Age, probs = 0.95, na.rm = TRUE)) |> 
#   ggplot(aes(Age, color = as.factor(Year))) + 
#   geom_density(adjust = 3, fill = NA)
```

```{r filter species 2}
#| message: false

hlcod <- bits_hl |>
  filter(SpecCode %in% c("126436", "164712")) |> 
  mutate(Species = "Gadus morhua")

hlfle <- bits_hl |>
  filter(SpecCode %in% c("127141", "172894")) |> 
  mutate(Species = "Platichthys flesus")

hlpla <- bits_hl |>
  filter(SpecCode %in% c("127143", "172902")) |>
  mutate(Species = "Pleuronectes platessa")

hldab <- bits_hl |>
  filter(SpecCode %in% c("127139", "172881")) |> 
  mutate(Species = "Limanda limanda")

# Check number of hauls per species
hlcod |> distinct(haul.id) |> nrow()
hlfle |> distinct(haul.id) |> nrow()
hlpla |> distinct(haul.id) |> nrow()
hldab |> distinct(haul.id) |> nrow()
bits_hh |> distinct(haul.id) |> nrow()

```

#### Prepare to add 0 catches

```{r add zero catches}
#| message: false

# Find common columns in the HH and HL data (here already subset by species)
comcol <- intersect(names(hlcod), names(bits_hh))

# What is the proportion of zero-catch hauls?
# Here we don't have zero catches
hlcod |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(HLNoAtLngt)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  distinct(zero_catch)

# Cod: Add 0s and then remove lines with SpecVal = 0 (first NA because we don't have a match in the HH, then make them 0 later)
hlcod0 <- full_join(hlcod, bits_hh[, comcol], by = comcol)

# No zeroes yet
hlcod0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(HLNoAtLngt)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  distinct(zero_catch) 

hlcod0$SpecVal[is.na(hlcod0$SpecVal)] <- "zeroCatch"

hlcod0$SpecVal <- factor(hlcod0$SpecVal)

hlcod0 <- hlcod0 |> filter(!SpecVal == "0")

# Add species again after merge
hlcod0$Species <- "Gadus morhua"

# Flounder: Add 0s, remove them if StdSpecRecCode !=1 and then remove lines with SpecVal = 0
hlfle0 <- full_join(hlfle, bits_hh[, comcol], by = comcol)

hlfle0 <- hlfle0[!(is.na(hlfle0$Species) & hlfle0$StdSpecRecCode != 1), ] 

hlfle0$SpecVal[is.na(hlfle0$SpecVal)] <- "zeroCatch"
hlfle0$SpecVal <- factor(hlfle0$SpecVal)

hlfle0 <- hlfle0 |> filter(!SpecVal == "0")

hlfle0$Species<-"Platichthys flesus"

# Plaice: Add 0s, remove them if StdSpecRecCode !=1 and then remove lines with SpecVal = 0
hlpla0 <- full_join(hlpla, bits_hh[, comcol], by = comcol)

hlpla0 <- hlpla0[!(is.na(hlpla0$Species) & hlpla0$StdSpecRecCode != 1), ] 

hlpla0$SpecVal[is.na(hlpla0$SpecVal)] <- "zeroCatch"
hlpla0$SpecVal <- factor(hlpla0$SpecVal)

hlpla0 <- hlpla0 |> filter(!SpecVal == "0")

hlpla0$Species<-"Pleuronectes platessa"

# Dab: Add 0s, remove them if StdSpecRecCode !=1 and then remove lines with SpecVal = 0
hldab0 <- full_join(hldab, bits_hh[, comcol], by = comcol)

hldab0 <- hldab0[!(is.na(hldab0$Species) & hldab0$StdSpecRecCode != 1), ] 

hldab0$SpecVal[is.na(hldab0$SpecVal)] <- "zeroCatch"
hldab0$SpecVal <- factor(hldab0$SpecVal)

hldab0 <- hldab0 |> filter(!SpecVal == "0")

hldab0$Species<-"Limanda limanda"

# Check number of hauls per species
hlcod0 |> distinct(haul.id) |> nrow()
hlfle0 |> distinct(haul.id) |> nrow()
hlpla0 |> distinct(haul.id) |> nrow()
hldab0 |> distinct(haul.id) |> nrow()
```

#### Create (unstandardized) CPUE for `SpecVal=1`. If `DataType=C` then `CPUEun=HLNoAtLngt`, if `DataType=R` then `CPUEun=HLNoAtLngt/(HaulDur/60)`, if `DataType=S` then `CPUEun=(HLNoAtLngt*SubFactor)/(HaulDur/60)`. If `SpecVal="zeroCatch"` then `CPUEun=0`, if `SpecVal=4` we need to decide (no length measurements, only total catch). Note that here we also add zero CPUE if `SpecVal=="zeroCatch"`.

Then I will sum for the same haul the CPUE of the same length classes if they were sampled with different subfactors or with different sexes.

```{r calculate cpue}
#| message: false

# Cod
hlcod0 <- hlcod0 |>
  mutate(CPUEun = ifelse(SpecVal == "1" & DataType == "C",
                         HLNoAtLngt,
                         
                         ifelse(SpecVal == "1" & DataType == "R",
                                HLNoAtLngt/(HaulDur/60),
                                
                                ifelse(SpecVal == "1" & DataType == "S",
                                       (HLNoAtLngt*SubFactor)/(HaulDur/60),
                                       
                                       ifelse(SpecVal == "zeroCatch", 0, NA)))))

# Plot and fill by zero catch
hlcod0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlcod0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")

# Some rows have multiple rows per combination of length class and haul id (i suppose often because it's split by sex), so we need to sum it up 
hlcod0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> distinct(n)
hlcod0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2) |> as.data.frame() |> head(20)
test <- hlcod0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2)
test_id <- test$haul.id[2]

hlcodL <- hlcod0 |> 
  group_by(LngtClass, haul.id) |> 
  mutate(CPUEun = sum(CPUEun)) |>
  ungroup() |> 
  mutate(id3 = paste(haul.id, LngtClass)) |> 
  distinct(id3, .keep_all = TRUE) |> 
  dplyr::select(-id3) # Clean up a bit

# Check with an ID
filter(hlcod0, haul.id == test_id)
filter(hlcodL, haul.id == test_id) |> as.data.frame()

# Do we still have 0 catches?
hlcodL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlcodL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")


# Flounder
hlfle0 <- hlfle0 |>
  mutate(CPUEun = ifelse(SpecVal == "1" & DataType == "C",
                         HLNoAtLngt,
                         
                         ifelse(SpecVal == "1" & DataType == "R",
                                HLNoAtLngt/(HaulDur/60),
                                
                                ifelse(SpecVal == "1" & DataType == "S",
                                       (HLNoAtLngt*SubFactor)/(HaulDur/60),
                                       
                                       ifelse(SpecVal == "zeroCatch", 0, NA)))))

# Plot and fill by zero catch
hlfle0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlfle0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")

# Some rows have multiple rows per combination of length class and haul id (i suppose often because it's split by sex), so we need to sum it up 
hlfle0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> distinct(n)
hlfle0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2) |> as.data.frame() |> head(20)
test <- hlfle0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2)
test_id <- test$haul.id[2]

hlfleL <- hlfle0 |> 
  group_by(LngtClass, haul.id) |> 
  mutate(CPUEun = sum(CPUEun)) |>
  ungroup() |> 
  mutate(id3 = paste(haul.id, LngtClass)) |> 
  distinct(id3, .keep_all = TRUE) |> 
  dplyr::select(-id3) # Clean up a bit

# Check with an ID
filter(hlfle0, haul.id == test_id)
filter(hlfleL, haul.id == test_id) |> as.data.frame()

# Do we still have 0 catches?
hlfleL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlfleL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")


# Plaice
hlpla0 <- hlpla0 |>
  mutate(CPUEun = ifelse(SpecVal == "1" & DataType == "C",
                         HLNoAtLngt,
                         
                         ifelse(SpecVal == "1" & DataType == "R",
                                HLNoAtLngt/(HaulDur/60),
                                
                                ifelse(SpecVal == "1" & DataType == "S",
                                       (HLNoAtLngt*SubFactor)/(HaulDur/60),
                                       
                                       ifelse(SpecVal == "zeroCatch", 0, NA)))))

# Plot and fill by zero catch
hlpla0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlpla0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")

# Some rows have multiple rows per combination of length class and haul id (i suppose often because it's split by sex), so we need to sum it up 
hlpla0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> distinct(n)
hlpla0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2) |> as.data.frame() |> head(20)
test <- hlpla0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2)
test_id <- test$haul.id[2]

hlplaL <- hlpla0 |> 
  group_by(LngtClass, haul.id) |> 
  mutate(CPUEun = sum(CPUEun)) |>
  ungroup() |> 
  mutate(id3 = paste(haul.id, LngtClass)) |> 
  distinct(id3, .keep_all = TRUE) |> 
  dplyr::select(-id3) # Clean up a bit

# Check with an ID
filter(hlpla0, haul.id == test_id)
filter(hlplaL, haul.id == test_id) |> as.data.frame()

# Do we still have 0 catches?
hlplaL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hlplaL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")


# Dab
hldab0 <- hldab0 |>
  mutate(CPUEun = ifelse(SpecVal == "1" & DataType == "C",
                         HLNoAtLngt,
                         
                         ifelse(SpecVal == "1" & DataType == "R",
                                HLNoAtLngt/(HaulDur/60),
                                
                                ifelse(SpecVal == "1" & DataType == "S",
                                       (HLNoAtLngt*SubFactor)/(HaulDur/60),
                                       
                                       ifelse(SpecVal == "zeroCatch", 0, NA)))))

# Plot and fill by zero catch
hldab0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hldab0 |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")

# Some rows have multiple rows per combination of length class and haul id (i suppose often because it's split by sex), so we need to sum it up 
hldab0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> distinct(n)
hldab0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2) |> as.data.frame() |> head(20)
test <- hldab0 |> group_by(LngtClass, haul.id) |> mutate(n = n()) |> ungroup() |> filter(n == 2)
test_id <- test$haul.id[2]

hldabL <- hldab0 |> 
  group_by(LngtClass, haul.id) |> 
  mutate(CPUEun = sum(CPUEun)) |>
  ungroup() |> 
  mutate(id3 = paste(haul.id, LngtClass)) |> 
  distinct(id3, .keep_all = TRUE) |> 
  dplyr::select(-id3) # Clean up a bit

# Check with an ID
filter(hldab0, haul.id == test_id)
filter(hldabL, haul.id == test_id) |> as.data.frame()

# Do we still have 0 catches?
hldabL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  filter(!CPUEun_haul == 0)

hldabL |>
  group_by(haul.id, Year) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |>
  group_by(Year, zero_catch) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = Year, y = n, fill = zero_catch)) +
  geom_bar(stat = "identity")
```

#### Get and add annual weight-length relationships from the CA data so that I can calculate CPUE in biomass rather than numbers further down

```{r lw pars}
#| message: false

# Cod
bits_ca_cod <- bits_ca |> 
  filter(SpecCode %in% c("164712", "126436")) |> 
  mutate(StNo = as.numeric(StNo)) |> 
  mutate(Species = "Cod") |> 
  mutate(ID = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

# Now I need to copy rows with NoAtLngt > 1 so that 1 row = 1 ind
# First make a small test
# nrow(bits_ca_cod)
# test_id <- head(filter(bits_ca_cod, CANoAtLngt == 5))$ID[1]
# filter(bits_ca_cod, ID == test_id & CANoAtLngt == 5)

bits_ca_cod <- bits_ca_cod %>% map_df(., rep, .$CANoAtLngt)

# head(data.frame(filter(bits_ca_cod, ID == test_id & CANoAtLngt == 5)), 20)
# nrow(bits_ca_cod)
# Looks ok!

# Standardize length and drop NA weights (need that for condition)
bits_ca_cod <- bits_ca_cod |> 
  drop_na(IndWgt) |> 
  drop_na(LngtClass) |> 
  filter(IndWgt > 0 & LngtClass > 0) |>  # Filter positive length and weight
  mutate(weight_kg = IndWgt/1000) |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) # Standardize length ((https://vocab.ices.dk/?ref=18))

# Plot
ggplot(bits_ca_cod, aes(IndWgt, length_cm)) +
  geom_point() + 
  facet_wrap(~Year)

# Now extract the coefficients for each year (not bothering with outliers at the moment)
cod_intercept <- bits_ca_cod %>% 
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "(Intercept)") |> 
  mutate(a = exp(estimate)) |> 
  mutate(Year = as.integer(Year)) |> 
  dplyr::select(Year, a)

cod_slope <- bits_ca_cod %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "log(length_cm)") |> 
  mutate(Year = as.integer(Year)) |> 
  rename("b" = "estimate") |> 
  dplyr::select(Year, b)

mean(cod_intercept$a)
mean(cod_slope$b)

# Flounder
bits_ca_fle <- bits_ca |> 
  filter(SpecCode %in% c("127141", "172894")) |> 
  mutate(StNo = as.numeric(StNo)) |> 
  mutate(Species = "Flounder") |> 
  mutate(ID = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

bits_ca_fle <- bits_ca_fle %>% map_df(., rep, .$CANoAtLngt)

# Standardize length and drop NA weights (need that for condition)
bits_ca_fle <- bits_ca_fle |> 
  drop_na(IndWgt) |> 
  drop_na(LngtClass) |> 
  filter(IndWgt > 0 & LngtClass > 0) |>  # Filter positive length and weight
  mutate(weight_kg = IndWgt/1000) |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) |> # Standardize length ((https://vocab.ices.dk/?ref=18))
  mutate(keep = ifelse(LngtCode == "." & Year == 2008, "N", "Y")) |>
  filter(keep == "Y") |> 
  filter(length_cm < 70)

# Plot
ggplot(bits_ca_fle, aes(IndWgt, length_cm, color = LngtCode)) +
  geom_point() + 
  facet_wrap(~Year)

# Now extract the coefficients for each year (not bothering with outliers at the moment)
fle_intercept <- bits_ca_fle %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "(Intercept)") |> 
  mutate(a = exp(estimate)) |> 
  mutate(Year = as.integer(Year)) |> 
  dplyr::select(Year, a)

fle_slope <- bits_ca_fle %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "log(length_cm)") |> 
  mutate(Year = as.integer(Year)) |> 
  rename("b" = "estimate") |> 
  dplyr::select(Year, b)

mean(fle_intercept$a)
mean(fle_slope$b)


# Plaice
bits_ca_pla <- bits_ca |> 
  filter(SpecCode %in% c("127143", "172902")) |> 
  mutate(StNo = as.numeric(StNo)) |> 
  mutate(Species = "Plaice") |> 
  mutate(ID = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

bits_ca_pla <- bits_ca_pla %>% map_df(., rep, .$CANoAtLngt)

# Standardize length and drop NA weights (need that for condition)
bits_ca_pla <- bits_ca_pla |> 
  drop_na(IndWgt) |> 
  drop_na(LngtClass) |> 
  filter(IndWgt > 0 & LngtClass > 0) |>  # Filter positive length and weight
  mutate(weight_kg = IndWgt/1000) |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) |> # Standardize length ((https://vocab.ices.dk/?ref=18))
  mutate(keep = ifelse(LngtCode == "." & Year == 2008, "N", "Y")) |>
  filter(keep == "Y") |> 
  filter(length_cm < 70)

# Plot
ggplot(bits_ca_pla, aes(IndWgt, length_cm, color = LngtCode)) +
  geom_point() + 
  facet_wrap(~Year)

# Now extract the coefficients for each year (not bothering with outliers at the moment)
pla_intercept <- bits_ca_pla %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "(Intercept)") |> 
  mutate(a = exp(estimate)) |> 
  mutate(Year = as.integer(Year)) |> 
  dplyr::select(Year, a)

pla_slope <- bits_ca_pla %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "log(length_cm)") |> 
  mutate(Year = as.integer(Year)) |> 
  rename("b" = "estimate") |> 
  dplyr::select(Year, b)

mean(pla_intercept$a)
mean(pla_slope$b)


# Dab
bits_ca_dab <- bits_ca |> 
  filter(SpecCode %in% c("127139", "172881")) |> 
  mutate(StNo = as.numeric(StNo)) |> 
  mutate(Species = "Dab") |> 
  mutate(ID = paste(Year, Quarter, Country, Ship, Gear, StNo, HaulNo, sep = "."))

bits_ca_dab <- bits_ca_dab %>% map_df(., rep, .$CANoAtLngt)

# Standardize length and drop NA weights (need that for condition)
bits_ca_dab <- bits_ca_dab |> 
  drop_na(IndWgt) |> 
  drop_na(LngtClass) |> 
  filter(IndWgt > 0 & LngtClass > 0) |>  # Filter positive length and weight
  mutate(weight_kg = IndWgt/1000) |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) |> # Standardize length ((https://vocab.ices.dk/?ref=18))
  mutate(keep = ifelse(LngtCode == "." & Year == 2008, "N", "Y")) |>
  filter(keep == "Y") |> 
  filter(length_cm < 70)

# Plot
ggplot(bits_ca_dab, aes(IndWgt, length_cm, color = LngtCode)) +
  geom_point() + 
  facet_wrap(~Year)

bits_ca_dab <- bits_ca_dab |> filter(IndWgt < 1000)

# Now extract the coefficients for each year (not bothering with outliers at the moment)
dab_intercept <- bits_ca_dab %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "(Intercept)") |> 
  mutate(a = exp(estimate)) |> 
  mutate(Year = as.integer(Year)) |> 
  dplyr::select(Year, a)

dab_slope <- bits_ca_dab %>%
  split(.$Year) |> 
  purrr::map(~lm(log(IndWgt) ~ log(length_cm), data = .x)) |>
  purrr::map_df(broom::tidy, .id = 'Year') |>
  filter(term == "log(length_cm)") |> 
  mutate(Year = as.integer(Year)) |> 
  rename("b" = "estimate") |> 
  dplyr::select(Year, b)

mean(dab_intercept$a)
mean(dab_slope$b)
```

#### Join the annual L-W relationships to the respective catch data to calculate CPUE in biomass not abundance

```{r join lw}
#| message: false

# These are the haul-data
# hlcodL
# hlfleL
# hlplaL
# hldabL

hlcodL <- left_join(hlcodL, cod_intercept, by = "Year")
hlcodL <- left_join(hlcodL, cod_slope, by = "Year")

hlfleL <- left_join(hlfleL, fle_intercept, by = "Year")
hlfleL <- left_join(hlfleL, fle_slope, by = "Year")

hlplaL <- left_join(hlplaL, pla_intercept, by = "Year")
hlplaL <- left_join(hlplaL, pla_slope, by = "Year")

# Now replace NA a and b (don't have individual data for all years) with the mean
hlplaL <- hlplaL |> 
  mutate(a = ifelse(is.na(a), mean(a, na.rm = TRUE), a),
         b = ifelse(is.na(b), mean(b, na.rm = TRUE), b))

hldabL <- left_join(hldabL, dab_intercept, by = "Year")
hldabL <- left_join(hldabL, dab_slope, by = "Year")

# Now replace NA a and b (don't have individual data for all years) with the mean
hldabL <- hldabL |> 
  mutate(a = ifelse(is.na(a), mean(a, na.rm = TRUE), a),
         b = ifelse(is.na(b), mean(b, na.rm = TRUE), b))
```

#### Convert from CPUE in numbers to $\text{kg/km}^2$

```{r cpue in weight}
#| message: false

# Cod
# First standardize length to cm and then check how zero-catches are implemented at this stage
hlcodL <- hlcodL |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) # Standardize length ((https://vocab.ices.dk/?ref=18))

filter(hlcodL, length_cm == 0) # No such thing

# Now check if all rows where length is NA are the ones with zero catch!
hlcodL |> 
  mutate(length2 = replace_na(length_cm, -9),
         no_length = ifelse(length2 < 0, "T", "F")) |> 
  ggplot(aes(length2, CPUEun, color = no_length)) + geom_point(alpha = 0.2) + facet_wrap(~no_length)

hlcodL |> filter(CPUEun == 0) |> distinct(length_cm)

# Right, so all hauls with zero catch have NA length_cm. I don't have any NA catches
t <- hlcodL |> drop_na(CPUEun)
t <- hlcodL |> filter(CPUEun == 0)
t <- hlcodL |> drop_na(length_cm)

# In other words, a zero catch is when the catch is zero and length_cm is NA
# In order to not get any NA CPUEs in unit biomass because length is NA (I want them instead
# to be 0, as the numbers-CPUE is), I will replace length_cm == NA with length_cm == 0 before
# calculating biomass CPUE
hlcodL <- hlcodL |> mutate(length_cm2 = replace_na(length_cm, 0))

# Standardize length in the haul-data and calculate weight
hlcodL <- hlcodL |> 
  mutate(weight_kg = (a*length_cm2^b)/1000) |> 
  mutate(CPUEun_kg = weight_kg*CPUEun)

# Plot and check it's correct also in this data
ggplot(hlcodL, aes(weight_kg, length_cm2)) +
  geom_point() + 
  facet_wrap(~Year)

# Hmm, some unrealistic weights actually
hlcodL |> arrange(desc(weight_kg)) |> as.data.frame() |> head(20)
hlcodL <- hlcodL |> filter(weight_kg < 100 & length_cm2 < 135)

ggplot(hlcodL, aes(weight_kg, length_cm2)) +
  geom_point() + 
  facet_wrap(~Year)


# Flounder
# First standardize length to cm and then check how zero-catches are implemented at this stage
hlfleL <- hlfleL |> 
  mutate(length_cm = ifelse(LngtCode %in% c(".", "0"), 
                            LngtClass/10,
                            LngtClass)) # Standardize length (https://vocab.ices.dk/?ref=18)

filter(hlfleL, length_cm == 0) # No such thing

bits_ca_fle <- bits_ca_fle |> 
  drop_na(IndWgt) |> 
  drop_na(LngtClass) |> 
  filter(IndWgt > 0 & LngtClass > 0) |>  # Filter positive length and weight
  mutate(weight_kg = IndWgt/1000) |> 
  mutate(length_cm = ifelse(LngtCode == ".", 
                            LngtClass/10,
                            LngtClass)) |> # Standardize length ((https://vocab.ices.dk/?ref=18))
  mutate(keep = ifelse(LngtCode == "." & Year == 2008, "N", "Y")) |>
  filter(keep == "Y") |> 
  filter(length_cm < 70)

# Now check if all rows where length is NA are the ones with zero catch!
hlfleL |> 
  mutate(length2 = replace_na(length_cm, -9),
         no_length = ifelse(length2 < 0, "T", "F")) |> 
  ggplot(aes(length2, CPUEun, color = no_length)) + geom_point(alpha = 0.2) + facet_wrap(~no_length)

hlfleL |> mutate(length2 = replace_na(length_cm, -9)) |> group_by(length2) |> distinct(CPUEun) |> arrange(CPUEun)

# Right, so all hauls with zero catch have NA length_cm. I don't have any NA catches
t <- hlfleL |> drop_na(CPUEun)
# Well, 11 rows. I will remove them
hlfleL <- hlfleL |> drop_na(CPUEun)
t <- hlfleL |> filter(CPUEun == 0) |> distinct(length_cm)
t <- hlfleL |> drop_na(length_cm)

# In other words, a zero catch is when the catch is zero and length_cm is NA
# In order to not get any NA CPUEs in unit biomass because length is NA (I want them instead
# to be 0, as the numbers-CPUE is), I will replace length_cm == NA with length_cm == 0 before
# calculating biomass cpue
hlfleL <- hlfleL |> mutate(length_cm2 = replace_na(length_cm, 0))

# Standardize length in the haul-data and calculate weight
hlfleL <- hlfleL |> 
  mutate(weight_kg = (a*length_cm2^b)/1000) |> 
  mutate(CPUEun_kg = weight_kg*CPUEun)

# Plot and check it's correct also in this data
ggplot(hlfleL, aes(weight_kg, length_cm2)) +
  geom_point() + 
  facet_wrap(~Year)

# Check
t <- hlfleL |> drop_na(CPUEun_kg) # Should not have any NA in biomass-catch
t <- hlfleL |> filter(CPUEun_kg == 0) # Should result in a few percent of rows (note this is not proportion of hauls, but rows)
t <- hlfleL |> drop_na(length_cm2) # Should be no NA


# Plaice
# First standardize length to cm and then check how zero-catches are implemented at this stage
hlplaL <- hlplaL |> 
  mutate(length_cm = ifelse(LngtCode %in% c(".", "0"), 
                            LngtClass/10,
                            LngtClass)) # Standardize length (https://vocab.ices.dk/?ref=18)

filter(hlplaL, length_cm == 0) # No such thing

# Now check if all rows where length is NA are the ones with zero catch!
hlplaL |> 
  mutate(length2 = replace_na(length_cm, -9),
         no_length = ifelse(length2 < 0, "T", "F")) |> 
  ggplot(aes(length2, CPUEun, color = no_length)) + geom_point(alpha = 0.2) + facet_wrap(~no_length)

hlplaL |> mutate(length2 = replace_na(length_cm, -9)) |> group_by(length2) |> distinct(CPUEun) |> arrange(CPUEun)

# Right, so all hauls with zero catch have NA length_cm. I don't have any NA catches (but I do)
t <- hlplaL |> drop_na(CPUEun)
hlplaL <- hlplaL |> drop_na(CPUEun)

# In other words, a zero catch is when the catch is zero and length_cm is NA
# In order to not get any NA CPUEs in unit biomass because length is NA (I want them instead
# to be 0, as the numbers-CPUE is), I will replace length_cm == NA with length_cm == 0 before
# calculating biomass cpue
hlplaL <- hlplaL |> mutate(length_cm2 = replace_na(length_cm, 0))

# Standardize length in the haul-data and calculate weight
hlplaL <- hlplaL |> 
  mutate(weight_kg = (a*length_cm2^b)/1000) |> 
  mutate(CPUEun_kg = weight_kg*CPUEun)

# Plot and check it's correct also in this data
ggplot(hlplaL, aes(weight_kg, length_cm2)) +
  geom_point() + 
  facet_wrap(~Year)

# Check
t <- hlfleL |> drop_na(CPUEun_kg) # Should not have any NA in biomass-catch
t <- hlfleL |> filter(CPUEun_kg == 0) # Should result in a few percent of rows (note this is not proportion of hauls, but rows)
t <- hlfleL |> drop_na(length_cm2) # Should be no NA


# Dab
# First standardize length to cm and then check how zero-catches are implemented at this stage
hldabL <- hldabL |> 
  mutate(length_cm = ifelse(LngtCode %in% c(".", "0"), 
                            LngtClass/10,
                            LngtClass)) # Standardize length (https://vocab.ices.dk/?ref=18)

filter(hldabL, length_cm == 0) # No such thing

# Now check if all rows where length is NA are the ones with zero catch!
hldabL |> 
  mutate(length2 = replace_na(length_cm, -9),
         no_length = ifelse(length2 < 0, "T", "F")) |> 
  ggplot(aes(length2, CPUEun, color = no_length)) + geom_point(alpha = 0.2) + facet_wrap(~no_length)

hldabL |> mutate(length2 = replace_na(length_cm, -9)) |> group_by(length2) |> distinct(CPUEun) |> arrange(CPUEun)

# Right, so all hauls with zero catch have NA length_cm. I don't have any NA catches
t <- hldabL |> drop_na(CPUEun)

# In other words, a zero catch is when the catch is zero and length_cm is NA
# In order to not get any NA CPUEs in unit biomass because length is NA (I want them instead
# to be 0, as the numbers-CPUE is), I will replace length_cm == NA with length_cm == 0 before
# calculating biomass cpue
hldabL <- hldabL |> mutate(length_cm2 = replace_na(length_cm, 0))

# Standardize length in the haul-data and calculate weight
hldabL <- hldabL |> 
  mutate(weight_kg = (a*length_cm2^b)/1000) |> 
  mutate(CPUEun_kg = weight_kg*CPUEun)

# Plot and check it's correct also in this data
ggplot(hldabL, aes(weight_kg, length_cm2)) +
  geom_point() + 
  facet_wrap(~Year)

# Check
t <- hldabL |> drop_na(CPUEun_kg) # Should not have any NA in biomass-catch
t <- hldabL |> filter(CPUEun_kg == 0) # Should result in a few percent of rows (note this is not proportion of hauls, but rows)
t <- hldabL |> drop_na(length_cm2) # Should be no NA
```

```{r proportion of zero-catch hauls}
cod_0plot <- hlcodL |>
  group_by(haul.id, Year, Quarter) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  group_by(Year, Quarter, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_zero_catch_hauls = Y/(N+Y),
         species = "Cod") 

fle_0plot <- hlfleL |>
  group_by(haul.id, Year, Quarter) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  group_by(Year, Quarter, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_zero_catch_hauls = Y/(N+Y),
         species = "Flounder")

pla_0plot <- hlplaL |>
  group_by(haul.id, Year, Quarter) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  group_by(Year, Quarter, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_zero_catch_hauls = Y/(N+Y),
         species = "Plaice")

dab_0plot <- hldabL |>
  group_by(haul.id, Year, Quarter) |>
  summarise(CPUEun_haul = sum(CPUEun)) |> 
  ungroup() |> 
  mutate(zero_catch = ifelse(CPUEun_haul == 0, "Y", "N")) |> 
  group_by(Year, Quarter, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_zero_catch_hauls = Y/(N+Y),
         species = "Dab")
```

#### Standardize according to Orio
To get unit: kg of fish caught by trawling for 1 h a standard bottom swept area of 0.45km2 using a TVL trawl with 75 m sweeps at the standard speed of three knots

```{r standardize}
#| message: false

# Remove hauls done with the TVL gear with a SweepLngt < 50 (these are calibration hauls, pers. com. Anders & Ale)
# And also hauls without length-information
# Remove pelagic gear
hlcodL <- hlcodL |>
  mutate(SweepLngt2 = replace_na(SweepLngt, 50)) |> 
  mutate(keep = ifelse(Gear == "TVL" & SweepLngt2 < 50, "N", "Y")) |> 
  filter(keep == "Y") |> 
  dplyr::select(-keep, -SweepLngt2) |> 
  filter(!Gear == "PEL")
  
hlfleL <- hlfleL |>
  mutate(SweepLngt2 = replace_na(SweepLngt, 50)) |> 
  mutate(keep = ifelse(Gear == "TVL" & SweepLngt2 < 50, "N", "Y")) |> 
  filter(keep == "Y") |> 
  dplyr::select(-keep, -SweepLngt2) |> 
  filter(!Gear == "PEL")

hlplaL <- hlplaL |>
  mutate(SweepLngt2 = replace_na(SweepLngt, 50)) |> 
  mutate(keep = ifelse(Gear == "TVL" & SweepLngt2 < 50, "N", "Y")) |> 
  filter(keep == "Y") |> 
  dplyr::select(-keep, -SweepLngt2) |> 
  filter(!Gear == "PEL")

hldabL <- hldabL |>
  mutate(SweepLngt2 = replace_na(SweepLngt, 50)) |> 
  mutate(keep = ifelse(Gear == "TVL" & SweepLngt2 < 50, "N", "Y")) |> 
  filter(keep == "Y") |> 
  dplyr::select(-keep, -SweepLngt2) |> 
  filter(!Gear == "PEL")

# Add in RS and RSA-values from the sweep file
# CPUE should be multiplied with RS and RSA to standardize to a relative speed and gear dimension.
# There is not a single file will all RS and RSA values. Instead they come in three files:
# - sweep (non-Swedish hauls between 1991-2016)
# - + calculated based on trawl speed and gear dimensions.
# I will join in the RS and RSA values from all sources, then standardize and filter
# away non-standardized hauls
# sort(unique(sweep$Year))
# sort(unique(sweep$Country))

# Since I don't have the sweep data for Swedish data, I have to calculate it from scratch using the 
# equation in Orio's spreadsheet

# First I will join in the sweep data, 
sweep_sel <- sweep |> rename("haul.id" = "ï..haul.id") |> dplyr::select(haul.id, RSA, RS)

hlcodL2 <- left_join(hlcodL, sweep_sel)
hlfleL2 <- left_join(hlfleL, sweep_sel)
hlplaL2 <- left_join(hlplaL, sweep_sel)
hldabL2 <- left_join(hldabL, sweep_sel)

hlcodL2 <- hlcodL2 |>
  rename("RS_sweep" = "RS",
         "RSA_sweep" = "RSA") |> 
  mutate(RS_sweep = as.numeric(RS_sweep),
         RSA_sweep = as.numeric(RSA_sweep))

hlfleL2 <- hlfleL2 |>
  rename("RS_sweep" = "RS",
         "RSA_sweep" = "RSA") |> 
  mutate(RS_sweep = as.numeric(RS_sweep),
         RSA_sweep = as.numeric(RSA_sweep))

hlplaL2 <- hlplaL2 |>
  rename("RS_sweep" = "RS",
         "RSA_sweep" = "RSA") |> 
  mutate(RS_sweep = as.numeric(RS_sweep),
         RSA_sweep = as.numeric(RSA_sweep))

hldabL2 <- hldabL2 |>
  rename("RS_sweep" = "RS",
         "RSA_sweep" = "RSA") |> 
  mutate(RS_sweep = as.numeric(RS_sweep),
         RSA_sweep = as.numeric(RSA_sweep))


# I will calculate a RS and RSA column in the catch data based on Ale's equation in the sweep file:
sort(unique(hlcodL2$GroundSpeed))
sort(unique(hlcodL2$Fishing.line))
sort(unique(hlcodL2$SweepLngt))

# First replace -9 in the columns I use for the calculations with NA so I don't end up with real numbers that are wrong!
hlcodL2 <- hlcodL2 |> mutate(GroundSpeed = ifelse(GroundSpeed == -9, NA, GroundSpeed),
                              Fishing.line = ifelse(Fishing.line == -9, NA, Fishing.line),
                              SweepLngt = ifelse(SweepLngt == -9, NA, SweepLngt))

hlfleL2 <- hlfleL2 |> mutate(GroundSpeed = ifelse(GroundSpeed == -9, NA, GroundSpeed),
                              Fishing.line = ifelse(Fishing.line == -9, NA, Fishing.line),
                              SweepLngt = ifelse(SweepLngt == -9, NA, SweepLngt))

hlplaL2 <- hlplaL2 |> mutate(GroundSpeed = ifelse(GroundSpeed == -9, NA, GroundSpeed),
                              Fishing.line = ifelse(Fishing.line == -9, NA, Fishing.line),
                              SweepLngt = ifelse(SweepLngt == -9, NA, SweepLngt))

hldabL2 <- hldabL2 |> mutate(GroundSpeed = ifelse(GroundSpeed == -9, NA, GroundSpeed),
                              Fishing.line = ifelse(Fishing.line == -9, NA, Fishing.line),
                              SweepLngt = ifelse(SweepLngt == -9, NA, SweepLngt))


hlcodL2 |> filter(Quarter == 1) |>
  distinct(GroundSpeed, Fishing.line, SweepLngt) |> as.data.frame() |> head(20)

hlcodL2 |> filter(Quarter == 4) |>
  distinct(GroundSpeed, Fishing.line, SweepLngt) |> as.data.frame() |> head(20)

# Hmm, Q1 has at least one of the RS or RSA variables as NAs. Will be difficult to standardize!
# Hope the correction factors are present in Ales conversion data

# Now calculate correction factors
hlcodL2 <- hlcodL2 |> mutate(RS_x = 3/GroundSpeed,
                             Horizontal.opening..m. = Fishing.line*0.67,
                             Swep.one.side..after.formula...meter = 0.258819045*SweepLngt, # SIN(RADIANS(15))
                             Size.final..m = Horizontal.opening..m. + (Swep.one.side..after.formula...meter*2),
                             Swept.area = (Size.final..m*3*1860)/1000000,
                             RSA_x = 0.45388309675081/Swept.area)

hlfleL2 <- hlfleL2 |> mutate(RS_x = 3/GroundSpeed,
                             Horizontal.opening..m. = Fishing.line*0.67,
                             Swep.one.side..after.formula...meter = 0.258819045*SweepLngt, # SIN(RADIANS(15))
                             Size.final..m = Horizontal.opening..m. + (Swep.one.side..after.formula...meter*2),
                             Swept.area = (Size.final..m*3*1860)/1000000,
                             RSA_x = 0.45388309675081/Swept.area)

hlplaL2 <- hlplaL2 |> mutate(RS_x = 3/GroundSpeed,
                             Horizontal.opening..m. = Fishing.line*0.67,
                             Swep.one.side..after.formula...meter = 0.258819045*SweepLngt, # SIN(RADIANS(15))
                             Size.final..m = Horizontal.opening..m. + (Swep.one.side..after.formula...meter*2),
                             Swept.area = (Size.final..m*3*1860)/1000000,
                             RSA_x = 0.45388309675081/Swept.area)

hldabL2 <- hldabL2 |> mutate(RS_x = 3/GroundSpeed,
                             Horizontal.opening..m. = Fishing.line*0.67,
                             Swep.one.side..after.formula...meter = 0.258819045*SweepLngt, # SIN(RADIANS(15))
                             Size.final..m = Horizontal.opening..m. + (Swep.one.side..after.formula...meter*2),
                             Swept.area = (Size.final..m*3*1860)/1000000,
                             RSA_x = 0.45388309675081/Swept.area)

# Check EQ. is correct by recalculating it in the sweep file
sweep <- sweep |> mutate(Horizontal.opening..m.2 = Fishing.line*0.67,
                         Swep.one.side..after.formula...meter2 = 0.258819045*SweepLngt, # SIN(RADIANS(15))
                         Size.final..m2 = Horizontal.opening..m.2 + (Swep.one.side..after.formula...meter2*2),
                         Swept.area2 = (Size.final..m2*3*1860)/1000000,
                         RSA_x = 0.45388309675081/Swept.area2)

sweep |>
  drop_na() |>
  ggplot(aes(as.numeric(RSA), RSA_x)) + geom_point() + geom_abline(intercept = 0, slope = 1)
# Yes it's the same

# Replace NAs with -1/3 (because ICES codes missing values as -9 and in the calculation above they get -1/3),
# so that I can filter them easily later
# sort(unique(hlcodL2$RS_x))
# sort(unique(hlcodL2$RSA_x))

hlcodL2$RS_x[is.na(hlcodL2$RS_x)] <- -1/3
hlcodL2$RS_sweep[is.na(hlcodL2$RS_sweep)] <- -1/3
hlcodL2$RSA_x[is.na(hlcodL2$RSA_x)] <- -1/3
hlcodL2$RSA_sweep[is.na(hlcodL2$RSA_sweep)] <- -1/3

hlfleL2$RS_x[is.na(hlfleL2$RS_x)] <- -1/3
hlfleL2$RS_sweep[is.na(hlfleL2$RS_sweep)] <- -1/3
hlfleL2$RSA_x[is.na(hlfleL2$RSA_x)] <- -1/3
hlfleL2$RSA_sweep[is.na(hlfleL2$RSA_sweep)] <- -1/3

hlplaL2$RS_x[is.na(hlplaL2$RS_x)] <- -1/3
hlplaL2$RS_sweep[is.na(hlplaL2$RS_sweep)] <- -1/3
hlplaL2$RSA_x[is.na(hlplaL2$RSA_x)] <- -1/3
hlplaL2$RSA_sweep[is.na(hlplaL2$RSA_sweep)] <- -1/3

hldabL2$RS_x[is.na(hldabL2$RS_x)] <- -1/3
hldabL2$RS_sweep[is.na(hldabL2$RS_sweep)] <- -1/3
hldabL2$RSA_x[is.na(hldabL2$RSA_x)] <- -1/3
hldabL2$RSA_sweep[is.na(hldabL2$RSA_sweep)] <- -1/3

# Compare the difference correction factors (calculated vs imported from sweep file)
p1 <- ggplot(filter(hlcodL2, RS_x > 0), aes(RS_x)) + geom_histogram() + xlim(0.4, 1.76)
p2 <- ggplot(hlcodL2, aes(RSA_x)) + geom_histogram()
p3 <- ggplot(hlcodL2, aes(RS_sweep)) + geom_histogram()
p4 <- ggplot(hlcodL2, aes(RSA_sweep)) + geom_histogram()

(p1 + p2) / (p3 + p4)

p5 <- ggplot(filter(hlfleL2, RS_x > 0), aes(RS_x)) + geom_histogram() + xlim(0.4, 1.76)
p6 <- ggplot(hlfleL2, aes(RSA_x)) + geom_histogram()
p7 <- ggplot(hlfleL2, aes(RS_sweep)) + geom_histogram()
p8 <- ggplot(hlfleL2, aes(RSA_sweep)) + geom_histogram()

(p5 + p6) / (p7 + p8)

p9 <- ggplot(filter(hlplaL2, RS_x > 0), aes(RS_x)) + geom_histogram() + xlim(0.4, 1.76)
p10 <- ggplot(hlplaL2, aes(RSA_x)) + geom_histogram()
p11 <- ggplot(hlplaL2, aes(RS_sweep)) + geom_histogram()
p12 <- ggplot(hlplaL2, aes(RSA_sweep)) + geom_histogram()

(p9 + p10) / (p11 + p12)

p13 <- ggplot(filter(hldabL2, RS_x > 0), aes(RS_x)) + geom_histogram() + xlim(0.4, 1.76)
p14 <- ggplot(hldabL2, aes(RSA_x)) + geom_histogram()
p15 <- ggplot(hldabL2, aes(RS_sweep)) + geom_histogram()
p16 <- ggplot(hldabL2, aes(RSA_sweep)) + geom_histogram()

(p13 + p14) / (p15 + p16)

# Why do I have RSA values smaller than one? (either because sweep length is longer or gear is larger (GOV))
# Check if I can calculate the same RSA in sweep as that entered there.
# Ok, so the equation is correct. Which ID's have RSA < 1?
hlcodL2 |> 
  filter(RSA_x < 1 & RSA_x > 0) |>
  dplyr::select(Year, Country, Ship, Gear, haul.id, Horizontal.opening..m., Fishing.line,
                Swep.one.side..after.formula...meter, SweepLngt, Size.final..m, Swept.area, RSA_x) |> 
  ggplot(aes(RSA_x, fill = factor(SweepLngt))) + geom_histogram() + facet_wrap(~Gear, ncol = 1)

# Check if I have more than one unique RS or RSA value per haul, or if it's "either this or that"
# Filter positive in both columns
hlcodL2 |> filter(RS_x > 0 & RS_sweep > 0) |> ggplot(aes(RS_x, RS_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

hlcodL2 |> filter(RSA_x > 0 & RSA_sweep > 0) |> ggplot(aes(RSA_x, RSA_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

hlfleL2 |> filter(RS_x > 0 & RS_sweep > 0) |> ggplot(aes(RS_x, RS_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

hlfleL2 |> filter(RSA_x > 0 & RSA_sweep > 0) |> ggplot(aes(RSA_x, RSA_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

# Ok, there's on odd RS_x that is larger than 3. It didn't catch anything and speed is 0.8! Will remove
hlcodL2 <- hlcodL2 |> filter(RS_x < 3)
hlfleL2 <- hlfleL2 |> filter(RS_x < 3)

# Plot again
hlcodL2 |> filter(RS_x > 0 & RS_sweep > 0) |> ggplot(aes(RS_x, RS_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

hlfleL2 |> filter(RS_x > 0 & RS_sweep > 0) |> ggplot(aes(RS_x, RS_sweep)) +
  geom_point() + geom_abline(aes(intercept = 0, slope = 1), color = "red")

# They are largely the same when they overlap. When they differ, I will use RS_sweep
# Make a single RS and RSA column

# Cod 
hlcodL3 <- hlcodL2 |>
  mutate(RS = -99,
         RS = ifelse(RS_sweep > 0, RS_sweep, RS),
         RS = ifelse(RS < 0 & RS_x > 0, RS_x, RS)) |> # Note that there are no NA i RS_x. This replaces all non-RS_sweep values -0.3, so I can filter positive later
  mutate(RSA = -99,
         RSA = ifelse(RSA_sweep > 0, RSA_sweep, RSA),
         RSA = ifelse(RSA < 0 & RSA_x > 0, RSA_x, RSA)) |>
  # filter(RS > 0) |>
  # filter(RSA > 0) |> 
  mutate(RSRSA = RS*RSA)

# Note, here I deviate from Orio (2017) and Lindmark (2022) and instead of removing
# NA values, I replace them with the mean by country and gear, following Smolinsky XXXX
hlcodL3 <- hlcodL3 |>
  mutate(RS = ifelse(RS < 0, NA, RS),
         RSA = ifelse(RSA < 0, NA, RSA)) |> 
  mutate(RSRSA = RS*RSA)

RSRSAmean <- hlcodL3 |>
  group_by(Country, Gear) |>
  summarise(RSRSAmean = mean(RSRSA, na.rm = T))

hlcodL3 <- hlcodL3 |>
  left_join(RSRSAmean) |>
  mutate(RSRSAimputed = ifelse(is.na(RSRSA), 1, 0),
         RSRSA = ifelse(is.na(RSRSA), RSRSAmean, RSRSA))

# Plot
ggplot(hlcodL3, aes(RSRSA)) + geom_histogram()


# Flounder 
hlfleL2 |> filter(Country == "LAT") |> distinct(Year) |> arrange(Year)

hlfleL3 <- hlfleL2 |>
  mutate(RS = -999,
         RS = ifelse(RS_sweep > 0, RS_sweep, RS),
         RS = ifelse(RS < 0, RS_x, RS)) |> # Note that there are no NA i RS_x. This replaces all non-RS_sweep values -0.3, so I can filter positive later
  mutate(RSA = -999,
         RSA = ifelse(RSA_sweep > 0, RSA_sweep, RSA),
         RSA = ifelse(RSA < 0, RSA_x, RSA)) |> 
  #filter(RS > 0) |>
  #filter(RSA > 0) |> 
  mutate(RSRSA = RS*RSA)

# Note, here I deviate from Orio (2017) and Lindmark (2022) and instead of removing
# NA values, I replace them with the mean by country and gear, following Smolinsky XXXX
hlfleL3 <- hlfleL3 |>
  mutate(RS = ifelse(RS < 0, NA, RS),
         RSA = ifelse(RSA < 0, NA, RSA)) |> 
  mutate(RSRSA = RS*RSA)

RSRSAmean <- hlfleL3 |>
  group_by(Country, Gear) |>
  summarise(RSRSAmean = mean(RSRSA, na.rm = T))

hlfleL3 <- hlfleL3 |>
  left_join(RSRSAmean) |>
  mutate(RSRSAimputed = ifelse(is.na(RSRSA), 1, 0),
         RSRSA = ifelse(is.na(RSRSA), RSRSAmean, RSRSA))

# Plot
ggplot(hlfleL3, aes(RSRSA)) + geom_histogram()

# Test how many years of LAT data I miss out on because I can't standardize it.
# hlfleL2 |>
#   mutate(RS = -999,
#          RS = ifelse(RS_sweep > 0, RS_sweep, RS),
#          RS = ifelse(RS < 0, RS_x, RS)) |> # Note that there are no NA i RS_x. This replaces all non-RS_sweep values -0.3, so I can filter positive later
#   filter(RS > 0) |> 
#   filter(Country == "LAT") |> 
#   distinct(Year) |> 
#   arrange(Year)
#   
# hlfleL2 |>
#   mutate(RSA = -999,
#          RSA = ifelse(RSA_sweep > 0, RSA_sweep, RSA),
#          RSA = ifelse(RSA < 0, RSA_x, RSA)) |> 
#   filter(RSA > 0) |> 
#   filter(Country == "LAT") |> 
#   distinct(Year) |> 
#   arrange(Year)

# Plaice 
hlplaL3 <- hlplaL2 |>
  mutate(RS = -99,
         RS = ifelse(RS_sweep > 0, RS_sweep, RS),
         RS = ifelse(RS < 0 & RS_x > 0, RS_x, RS)) |> # Note that there are no NA i RS_x. This replaces all non-RS_sweep values -0.3, so I can filter positive later
  mutate(RSA = -99,
         RSA = ifelse(RSA_sweep > 0, RSA_sweep, RSA),
         RSA = ifelse(RSA < 0 & RSA_x > 0, RSA_x, RSA)) |>
  # filter(RS > 0) |>
  # filter(RSA > 0) |> 
  mutate(RSRSA = RS*RSA)

# Note, here I deviate from Orio (2017) and Lindmark (2022) and instead of removing
# NA values, I replace them with the mean by country and gear, following Smolinsky XXXX
hlplaL3 <- hlplaL3 |>
  mutate(RS = ifelse(RS < 0, NA, RS),
         RSA = ifelse(RSA < 0, NA, RSA)) |> 
  mutate(RSRSA = RS*RSA)

RSRSAmean <- hlplaL3 |>
  group_by(Country, Gear) |>
  summarise(RSRSAmean = mean(RSRSA, na.rm = T))

hlplaL3 <- hlplaL3 |>
  left_join(RSRSAmean) |>
  mutate(RSRSAimputed = ifelse(is.na(RSRSA), 1, 0),
         RSRSA = ifelse(is.na(RSRSA), RSRSAmean, RSRSA))

# Plot
ggplot(hlplaL3, aes(RSRSA)) + geom_histogram()


# Dab 
hldabL3 <- hldabL2 |>
  mutate(RS = -99,
         RS = ifelse(RS_sweep > 0, RS_sweep, RS),
         RS = ifelse(RS < 0 & RS_x > 0, RS_x, RS)) |> # Note that there are no NA i RS_x. This replaces all non-RS_sweep values -0.3, so I can filter positive later
  mutate(RSA = -99,
         RSA = ifelse(RSA_sweep > 0, RSA_sweep, RSA),
         RSA = ifelse(RSA < 0 & RSA_x > 0, RSA_x, RSA)) |>
  # filter(RS > 0) |>
  # filter(RSA > 0) |> 
  mutate(RSRSA = RS*RSA)

# Note, here I deviate from Orio (2017) and Lindmark (2022) and instead of removing
# NA values, I replace them with the mean by country and gear, following Smolinsky XXXX
hldabL3 <- hldabL3 |>
  mutate(RS = ifelse(RS < 0, NA, RS),
         RSA = ifelse(RSA < 0, NA, RSA)) |> 
  mutate(RSRSA = RS*RSA)

RSRSAmean <- hldabL3 |>
  group_by(Country, Gear) |>
  summarise(RSRSAmean = mean(RSRSA, na.rm = T))

hldabL3 <- hldabL3 |>
  left_join(RSRSAmean) |>
  mutate(RSRSAimputed = ifelse(is.na(RSRSA), 1, 0),
         RSRSA = ifelse(is.na(RSRSA), RSRSAmean, RSRSA))

# Plot
ggplot(hldabL3, aes(RSRSA)) + geom_histogram()


# Standardize!
hlcodL3 <- hlcodL3 |>
  mutate(CPUEst_kg = CPUEun_kg*RS*RSA,
         CPUEst = CPUEun*RS*RSA)

hlfleL3 <- hlfleL3 |>
  mutate(CPUEst_kg = CPUEun_kg*RS*RSA,
         CPUEst = CPUEun*RS*RSA)

hlplaL3 <- hlplaL3 |>
  mutate(CPUEst_kg = CPUEun_kg*RS*RSA,
         CPUEst = CPUEun*RS*RSA)
  
hldabL3 <- hldabL3 |>
  mutate(CPUEst_kg = CPUEun_kg*RS*RSA,
         CPUEst = CPUEun*RS*RSA)


unique(is.na(hlcodL3$CPUEst_kg))
unique(is.na(hlcodL3$CPUEst))
min(hlcodL3$CPUEst_kg)
min(hlcodL3$CPUEst)

unique(is.na(hlfleL3$CPUEst_kg)) # Remove the few NA's here
hlfleL3 <- hlfleL3 |> drop_na(CPUEst_kg)
unique(is.na(hlfleL3$CPUEst))
min(hlfleL3$CPUEst_kg) 
min(hlfleL3$CPUEst)

unique(is.na(hlplaL3$CPUEst_kg))
unique(is.na(hlplaL3$CPUEst))
min(hlplaL3$CPUEst_kg)
min(hlplaL3$CPUEst)

unique(is.na(hldabL3$CPUEst_kg))
unique(is.na(hldabL3$CPUEst))
min(hldabL3$CPUEst_kg)
min(hldabL3$CPUEst)

# Now calculate CPUE PER LENGTH CLASS, then create the new unit, i.e.: convert from kg of fish caught by trawling for 1 h a standard bottom swept area of 0.45km2 (using a TVL trawl with 75 m sweeps at the standard speed of three knots) to... kg of fish per km^2 by dividing with 0.45

p1 <- ggplot(hlcodL3) +
  geom_histogram(aes(length_cm2, fill = "length_cm1"), alpha = 0.5)  

p2 <- ggplot(hlcodL3) +
  geom_histogram(aes(length_cm2, fill = "length_cm2"), alpha = 0.5) 

p1/p2


# Cod
hlcodhaul <- hlcodL3 |>
  mutate(cpue_kg = CPUEst_kg,
         cpue = CPUEst,
         cpue_kg_un = CPUEun_kg,
         cpue_un = CPUEun,
         density = cpue_kg/0.45,
         density_ab = cpue/0.45)

# Flounder
hlflehaul <- hlfleL3 |>
  mutate(cpue_kg = CPUEst_kg,
         cpue = CPUEst,
         cpue_kg_un = CPUEun_kg,
         cpue_un = CPUEun,
         density = cpue_kg/0.45,
         density_ab = cpue/0.45)

# Plaice
hlplahaul <- hlplaL3 |>
  mutate(cpue_kg = CPUEst_kg,
         cpue = CPUEst,
         cpue_kg_un = CPUEun_kg,
         cpue_un = CPUEun,
         density = cpue_kg/0.45,
         density_ab = cpue/0.45)

# Dab
hldabhaul <- hldabL3 |>
  mutate(cpue_kg = CPUEst_kg,
         cpue = CPUEst,
         cpue_kg_un = CPUEun_kg,
         cpue_un = CPUEun,
         density = cpue_kg/0.45,
         density_ab = cpue/0.45)

# First, figure out why I have length = 0 and density = 0 when I have other lengths in the haul
hlcodhaul |> filter(haul.id == "1993:1:GFR:SOL:H20:23:31") |> as.data.frame()

hlcodhaul |>
  group_by(haul.id) |> 
  mutate(no_catches = length(unique(CPUEun))) |> 
  filter(any(CPUEun == 0)) |> 
  filter(no_catches > 1) |> 
  as.data.frame() |> 
  head(20)

hlcodhaul |> 
  group_by(haul.id) |> 
  filter(CPUEun == min(CPUEun)) |> 
  ungroup() |> 
  distinct(CPUEun)

# The minimum CPUE in all hauls is always zero at this stage. It doesn't really matter because I calculate haul-level CPUE by grouping by ID's and summing. 

# Rename columns and select specific columns from the cod data
# Cod
datcod <- hlcodhaul |>
  dplyr::select(density, Year, ShootLat, ShootLong, Quarter, Country, Month, haul.id, IDx, Rect, sub_div, length_cm2, depth_obs) |> 
  rename(year = Year,
         month = Month,
         lat = ShootLat,
         lon = ShootLong,
         quarter = Quarter,
         ices_rect = Rect,
         length_cm = length_cm2) |> 
  mutate(species = "cod")

# Flounder
datfle <- hlflehaul |>
  dplyr::select(density, Year, ShootLat, ShootLong, Quarter, Country, Month, haul.id, IDx, Rect, sub_div, length_cm2, depth_obs) |> 
  rename(year = Year,
         month = Month,
         lat = ShootLat,
         lon = ShootLong,
         quarter = Quarter,
         ices_rect = Rect,
         length_cm = length_cm2) |> 
  mutate(species = "flounder")

# Plaice
datpla <- hlplahaul |>
  dplyr::select(density, Year, ShootLat, ShootLong, Quarter, Country, Month, haul.id, IDx, Rect, sub_div, length_cm2, depth_obs) |> 
  rename(year = Year,
         month = Month,
         lat = ShootLat,
         lon = ShootLong,
         quarter = Quarter,
         ices_rect = Rect,
         length_cm = length_cm2) |> 
  mutate(species = "plaice")

# Dab
datdab <- hldabhaul |>
  dplyr::select(density, Year, ShootLat, ShootLong, Quarter, Country, Month, haul.id, IDx, Rect, sub_div, length_cm2, depth_obs) |> 
  rename(year = Year,
         month = Month,
         lat = ShootLat,
         lon = ShootLong,
         quarter = Quarter,
         ices_rect = Rect,
         length_cm = length_cm2) |> 
  mutate(species = "dab")
```

```{r very long data with all combinations of size and haul id}
# Because it's size-based cpue, I want the data frame to be "full", so that each haul has every size, even if all are empty. That means I can define a size group, group by and sum for each haul, even if there aren't any sizes caught. Now I only have lengths with catches, and no lengths if catch is zero.
datcod |> group_by(haul.id) |> summarise(n_size = length(unique(length_cm))) |> distinct(n_size, .keep_all = TRUE)
datcod |> filter(haul.id == "1993:1:GFR:SOL:H20:23:31") |> as.data.frame()
datcod |> group_by(haul.id) |> mutate(tot_dens = sum(density)) |> ungroup() |> distinct(haul.id, .keep_all = TRUE) |> filter(tot_dens == 0)

# Create a data frame with all combinations of trawl IDs and lengths
ex_df <- data.frame(expand.grid(
  length_cm = seq_range(datcod$length_cm, by = 1),
  haul.id = unique(datcod$haul.id))
  )

# Create an ID that is haul + length
ex_df$haul.id.size <- paste(ex_df$haul.id, ex_df$length_cm, sep = ".")
datcod$haul.id.size <- paste(datcod$haul.id, datcod$length_cm, sep = ".")

# Remove IDs that are already in datcod
ex_df <- ex_df |> filter(!haul.id.size %in% unique(datcod$haul.id.size)) 

# Add in the other columns besides density and length
dat_for_join <- datcod |> dplyr::select(-density, -length_cm, -haul.id.size) |> distinct(haul.id, .keep_all = TRUE)

ex_df <- left_join(ex_df, dat_for_join, by = "haul.id")

datcod |> filter(haul.id.size %in% ex_df$haul.id.size)

# Bind_rows these data with datcod
nrow(datcod) + nrow(ex_df)

unique(is.na(datcod$density))

datcod <- bind_rows(datcod, ex_df) |> arrange(haul.id, length_cm)
nrow(datcod)
datcod

# Replace NA density with 0 density because that's the added length-classes not previously in the catch data
datcod <- datcod |> mutate(density = replace_na(density, 0))

# Check the proportion zeroes are still correct:
t <- datcod |>
  group_by(haul.id) |>
  summarise(haul_density = sum(density)) |> 
  ungroup()

nrow(datcod)
length(unique(datcod$haul.id))
t |> drop_na(haul_density)
nrow(t)
t |> filter(!haul_density == 0)


# Flounder
# Create a data frame with all combinations of trawl IDs and lengths
ex_df <- data.frame(expand.grid(
  length_cm = seq_range(datfle$length_cm, by = 1),
  haul.id = unique(datfle$haul.id))
  )

# Create an ID that is haul + length
ex_df$haul.id.size <- paste(ex_df$haul.id, ex_df$length_cm, sep = ".")
datfle$haul.id.size <- paste(datfle$haul.id, datfle$length_cm, sep = ".")

# Remove IDs that are already in datfle
ex_df <- ex_df |> filter(!haul.id.size %in% unique(datfle$haul.id.size)) 

# Add in the other columns besides density and length
dat_for_join <- datfle |> dplyr::select(-density, -length_cm, -haul.id.size) |> distinct(haul.id, .keep_all = TRUE)

ex_df <- left_join(ex_df, dat_for_join, by = "haul.id")

# Bind_rows these data with datfle
datfle <- bind_rows(datfle, ex_df) |> arrange(haul.id, length_cm)

# Replace NA density with 0 density because that's the added length-classes not previously in the catch data
datfle <- datfle |> mutate(density = replace_na(density, 0))


# Plaice
# Create a data frame with all combinations of trawl IDs and lengths
ex_df <- data.frame(expand.grid(
  length_cm = seq_range(datpla$length_cm, by = 1),
  haul.id = unique(datpla$haul.id))
  )

# Create an ID that is haul + length
ex_df$haul.id.size <- paste(ex_df$haul.id, ex_df$length_cm, sep = ".")
datpla$haul.id.size <- paste(datpla$haul.id, datpla$length_cm, sep = ".")

# Remove IDs that are already in datpla
ex_df <- ex_df |> filter(!haul.id.size %in% unique(datpla$haul.id.size)) 

# Add in the other columns besides density and length
dat_for_join <- datpla |> dplyr::select(-density, -length_cm, -haul.id.size) |> distinct(haul.id, .keep_all = TRUE)

ex_df <- left_join(ex_df, dat_for_join, by = "haul.id")

# Bind_rows these data with datpla
datpla <- bind_rows(datpla, ex_df) |> arrange(haul.id, length_cm)

# Replace NA density with 0 density because that's the added length-classes not previously in the catch data
datpla <- datpla |> mutate(density = replace_na(density, 0))


# Dab
# Create a data frame with all combinations of trawl IDs and lengths
ex_df <- data.frame(expand.grid(
  length_cm = seq_range(datdab$length_cm, by = 1),
  haul.id = unique(datdab$haul.id))
  )

# Create an ID that is haul + length
ex_df$haul.id.size <- paste(ex_df$haul.id, ex_df$length_cm, sep = ".")
datdab$haul.id.size <- paste(datdab$haul.id, datdab$length_cm, sep = ".")

# Remove IDs that are already in datdab
ex_df <- ex_df |> filter(!haul.id.size %in% unique(datdab$haul.id.size)) 

# Add in the other columns besides density and length
dat_for_join <- datdab |> dplyr::select(-density, -length_cm, -haul.id.size) |> distinct(haul.id, .keep_all = TRUE)

ex_df <- left_join(ex_df, dat_for_join, by = "haul.id")

# Bind_rows these data with datdab
datdab <- bind_rows(datdab, ex_df) |> arrange(haul.id, length_cm)

# Replace NA density with 0 density because that's the added length-classes not previously in the catch data
datdab <- datdab |> mutate(density = replace_na(density, 0))

# Merge all species data
dat <- bind_rows(datcod, datfle, datpla, datdab)

glimpse(dat)

# Check proportion zeroes
q1 <- dat |> 
  filter(quarter == 1) |> 
  group_by(species, haul.id) |> 
  mutate(zero_catch = ifelse(sum(density) == 0, "Y", "N")) |> 
  ungroup() |> 
  group_by(year, species, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_z = Y / (N+Y), 
         q = 1)  

q4 <- dat |> 
  filter(quarter == 4) |> 
  group_by(species, haul.id) |> 
  mutate(zero_catch = ifelse(sum(density) == 0, "Y", "N")) |> 
  ungroup() |> 
  group_by(year, species, zero_catch) |> 
  summarise(n = n()) |> 
  ungroup() |> 
  pivot_wider(names_from = zero_catch, values_from = n) |> 
  mutate(prop_z = Y / (N+Y), 
         q = 4)  

ggplot(bind_rows(q1, q4), aes(year, prop_z*100, color = factor(q))) +
  geom_line() +
  facet_wrap(~ species, ncol = 1)
```

## Add in the environmental variables

```{r add env vars}
# Only need 1 row per haul
dat <- dat |>
  mutate(month_year = paste(month, year, sep = "_"))
  
dat_haul <- dat |> 
  distinct(haul.id, .keep_all = TRUE) |>
  dplyr::select(lat, lon, year, month, quarter, month_year)
```

#### Oxygen

```{r oxygen}
# Downloaded from here: https://data.marine.copernicus.eu/products
# Extract raster points: https://gisday.wordpress.com/2014/03/24/extract-raster-values-from-points-using-r/comment-page-1/
# https://rpubs.com/boyerag/297592
# https://pjbartlein.github.io/REarthSysSci/netCDF.html#get-a-variable
# Open the netCDF file
ncin <- nc_open(paste0(home, "/data/NEMO/cmems_mod_bal_bgc_my_P1M-m_1691065496556.nc"))

print(ncin)

# Get longitude and latitude
lon <- ncvar_get(ncin,"lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin,"lat")
nlat <- dim(lat)
head(lat)

# Get time
time <- ncvar_get(ncin,"time")
time

tunits <- ncatt_get(ncin,"time","units")
nt <- dim(time)
nt
tunits

# Get oxygen
dname <- "o2b"

oxy_array <- ncvar_get(ncin,dname)
dlname <- ncatt_get(ncin,dname,"long_name")
dunits <- ncatt_get(ncin,dname,"units")
fillvalue <- ncatt_get(ncin,dname,"_FillValue")
dim(oxy_array)

# Get global attributes
title <- ncatt_get(ncin,0,"title")
institution <- ncatt_get(ncin,0,"institution")
datasource <- ncatt_get(ncin,0,"source")
references <- ncatt_get(ncin,0,"references")
history <- ncatt_get(ncin,0,"history")
Conventions <- ncatt_get(ncin,0,"Conventions")

# Convert time: split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

# Here I deviate from the guide a little bit. Save this info:
dates <- chron(time, origin = c(tmonth, tday, tyear))

# Crop the date variable
months <- as.numeric(substr(dates, 2, 3))
years <- as.numeric(substr(dates, 8, 9))
years <- ifelse(years > 90, 1900 + years, 2000 + years)

# Replace netCDF fill values with NA's
oxy_array[oxy_array == fillvalue$value] <- NA

dim(oxy_array)
str(dim(oxy_array))
# The third slot is the date index

# Loop through all "dates", put into a list 
dlist <- list()

for(i in 1:length(months)) {
  
  oxy_sub <- oxy_array[, , i]
    
  dlist[[i]] <- oxy_sub
  
}

# Name the list
names(dlist) <- paste(months, years, sep = "_")
str(dlist)

# Create data holding object
oxy_data_list <- list()

# This is our looping index: 
# unique(dat_haul$month_year)
# We do not have January 1993 in the oxygen raster. Replace that with february
dat_haul_month_year <- unique(dat_haul$month_year)
dat_haul_month_year[3] <- "2_1993"

# Loop through each month_year and extract raster values for the cpue data points
for(i in dat_haul_month_year) {
  
  # Set plot limits
  ymin = 54; ymax = 58; xmin = 12; xmax = 22

  # Subset a month-year combination
  oxy_slice <- dlist[[i]]
  
  # Create raster for that year (i)
  r <- raster(t(oxy_slice), xmn = min(lon), xmx = max(lon), ymn = min(lat), ymx = max(lat),
              crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
  
  # Flip...
  r <- flip(r, direction = 'y')
  
  plot(r, main = paste(i), ylim = c(ymin, ymax), xlim = c(xmin, xmax))

  # Filter the same year (i) in the cpue data and select only coordinates
  d_slice <- dat_haul |> filter(month_year == i) |> dplyr::select(lon, lat)
  
  # Make into a SpatialPoints object
  data_sp <- SpatialPoints(d_slice)
  
  # Extract raster value (oxygen)
  rasValue <- raster::extract(r, data_sp)
  
  # Now we want to plot the results of the raster extractions by plotting the cpue data points over a raster and saving it for each year.
  # Make the SpatialPoints object into a raster again (for plot)
  df <- as.data.frame(data_sp)
  
  # Add in the raster value in the df holding the coordinates for the cpue data
  d_slice$oxy <- rasValue
  
  # Add in which year
  d_slice$month_year <- i

  # Now the unit of oxygen is mmol/m3. I want it to be ml/L. The original model is in unit ml/L
  # and it's been converted by the data host. Since it was converted without accounting for
  # pressure or temperature, I can simply use the following conversion factor:
  # 1 ml/l = 103/22.391 = 44.661 μmol/l -> 1 ml/l = 0.044661 mmol/l = 44.661 mmol/m^3 -> 0.0223909 ml/l = 1mmol/m^3
  # https://ocean.ices.dk/tools/unitconversion.aspx

  d_slice$oxy <- d_slice$oxy * 0.0223909
    
  # Add each years' data in the list
  oxy_data_list[[i]] <- d_slice

}

# Now create a data frame from the list of all annual values
big_dat_oxy <- dplyr::bind_rows(oxy_data_list)
```

#### Temperature

```{r temperature}
# Open the netCDF file
ncin <- nc_open(paste0(home, "/data/NEMO/cmems_mod_bal_phy_my_P1M-m_1691065935335.nc"))
                                        
print(ncin)

# Get longitude and latitude
lon <- ncvar_get(ncin,"lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin,"lat")
nlat <- dim(lat)
head(lat)

# Get time
time <- ncvar_get(ncin,"time")
time

tunits <- ncatt_get(ncin,"time","units")
nt <- dim(time)
nt
tunits

# Get temperature
dname <- "bottomT"

temp_array <- ncvar_get(ncin,dname)
dlname <- ncatt_get(ncin,dname,"long_name")
dunits <- ncatt_get(ncin,dname,"units")
fillvalue <- ncatt_get(ncin,dname,"_FillValue")
dim(temp_array)

# Get global attributes
title <- ncatt_get(ncin,0,"title")
institution <- ncatt_get(ncin,0,"institution")
datasource <- ncatt_get(ncin,0,"source")
references <- ncatt_get(ncin,0,"references")
history <- ncatt_get(ncin,0,"history")
Conventions <- ncatt_get(ncin,0,"Conventions")

# Convert time: split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

# Here I deviate from the guide a little bit. Save this info:
dates <- chron(time, origin = c(tmonth, tday, tyear))

# Crop the date variable
months <- as.numeric(substr(dates, 2, 3))
years <- as.numeric(substr(dates, 8, 9))
years <- ifelse(years > 90, 1900 + years, 2000 + years)

# Replace netCDF fill values with NA's
temp_array[temp_array == fillvalue$value] <- NA

# Loop through all "dates", put into a list 
dlist <- list()

for(i in 1:length(months)) {
  
  temp_sub <- temp_array[, , i]
  
  dlist[[i]] <- temp_sub
  
}

# Name the list
names(dlist) <- paste(months, years, sep = "_")
str(dlist)

# Create data holding object
temp_data_list <- list()

# This is our looping index: 
# unique(dat_haul$month_year)
# We do not have January 1993 in the oxygen raster. Replace that with february
dat_haul_month_year <- unique(dat_haul$month_year)
dat_haul_month_year[3] <- "2_1993"

# Loop through each month_year and extract raster values for the cpue data points
for(i in dat_haul_month_year) {
  
  # Set plot limits
  ymin = 54; ymax = 58; xmin = 12; xmax = 22
  
  # Subset a month-year combination
  temp_slice <- dlist[[i]]
  
  # Create raster for that year (i)
  r <- raster(t(temp_slice), xmn = min(lon), xmx = max(lon), ymn = min(lat), ymx = max(lat),
              crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
  
  # Flip...
  r <- flip(r, direction = 'y')
  
  plot(r, main = paste(i), ylim = c(ymin, ymax), xlim = c(xmin, xmax))
  
  # Filter the same year (i) in the cpue data and select only coordinates
  d_slice <- dat_haul |> filter(month_year == i) |> dplyr::select(lon, lat)
  
  # Make into a SpatialPoints object
  data_sp <- SpatialPoints(d_slice)
  
  # Extract raster value (oxygen)
  rasValue <- raster::extract(r, data_sp)
  
  # Now we want to plot the results of the raster extractions by plotting the cpue data points over a raster and saving it for each year.
  # Make the SpatialPoints object into a raster again (for plot)
  df <- as.data.frame(data_sp)
  
  # Add in the raster value in the df holding the coordinates for the cpue data
  d_slice$temp <- rasValue
  
  # Add in which year
  d_slice$month_year <- i
  
  # Add each years' data in the list
  temp_data_list[[i]] <- d_slice
  
}

# Now create a data frame from the list of all annual values
big_dat_temp <- dplyr::bind_rows(temp_data_list)
```

#### Salinity

```{r salinity}
# Open the netCDF file
ncin <- nc_open(paste0(home, "/data/NEMO/cmems_mod_bal_phy_my_P1M-m_1691065974147.nc"))

print(ncin)

# Get longitude and latitude
lon <- ncvar_get(ncin,"lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin,"lat")
nlat <- dim(lat)
head(lat)

# Get time
time <- ncvar_get(ncin,"time")
time

tunits <- ncatt_get(ncin,"time","units")
nt <- dim(time)
nt
tunits

# Get Salinity
dname <- "sob"

sal_array <- ncvar_get(ncin,dname)
dlname <- ncatt_get(ncin,dname,"long_name")
dunits <- ncatt_get(ncin,dname,"units")
fillvalue <- ncatt_get(ncin,dname,"_FillValue")
dim(sal_array)

# Get global attributes
title <- ncatt_get(ncin,0,"title")
institution <- ncatt_get(ncin,0,"institution")
datasource <- ncatt_get(ncin,0,"source")
references <- ncatt_get(ncin,0,"references")
history <- ncatt_get(ncin,0,"history")
Conventions <- ncatt_get(ncin,0,"Conventions")

# Convert time: split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

# Here I deviate from the guide a little bit. Save this info:
dates <- chron(time, origin = c(tmonth, tday, tyear))

# Crop the date variable
months <- as.numeric(substr(dates, 2, 3))
years <- as.numeric(substr(dates, 8, 9))
years <- ifelse(years > 90, 1900 + years, 2000 + years)

# Replace netCDF fill values with NA's
sal_array[sal_array == fillvalue$value] <- NA

# Loop through all "dates", put into a list 
dlist <- list()

for(i in 1:length(months)) {
  
  sal_sub <- sal_array[, , i]
  
  dlist[[i]] <- sal_sub
  
}

# Name the list
names(dlist) <- paste(months, years, sep = "_")
str(dlist)

# Create data holding object
sal_data_list <- list()

# This is our looping index: 
# unique(dat_haul$month_year)
# We do not have January 1993 in the oxygen raster. Replace that with february
dat_haul_month_year <- unique(dat_haul$month_year)
dat_haul_month_year[3] <- "2_1993"

# Loop through each month_year and extract raster values for the cpue data points
for(i in dat_haul_month_year) {
  
  # Set plot limits
  ymin = 54; ymax = 58; xmin = 12; xmax = 22
  
  # Subset a month-year combination
  sal_slice <- dlist[[i]]
  
  # Create raster for that year (i)
  r <- raster(t(sal_slice), xmn = min(lon), xmx = max(lon), ymn = min(lat), ymx = max(lat),
              crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
  
  # Flip...
  r <- flip(r, direction = 'y')
  
  plot(r, main = paste(i), ylim = c(ymin, ymax), xlim = c(xmin, xmax))
  
  # Filter the same year (i) in the cpue data and select only coordinates
  d_slice <- dat_haul |> filter(month_year == i) |> dplyr::select(lon, lat)
  
  # Make into a SpatialPoints object
  data_sp <- SpatialPoints(d_slice)
  
  # Extract raster value (oxygen)
  rasValue <- raster::extract(r, data_sp)
  
  # Now we want to plot the results of the raster extractions by plotting the cpue data points over a raster and saving it for each year.
  # Make the SpatialPoints object into a raster again (for plot)
  df <- as.data.frame(data_sp)
  
  # Add in the raster value in the df holding the coordinates for the cpue data
  d_slice$sal <- rasValue
  
  # Add in which year
  d_slice$month_year <- i
  
  # Add each years' data in the list
  sal_data_list[[i]] <- d_slice
  
}

# Now create a data frame from the list of all annual values
big_dat_sal <- dplyr::bind_rows(sal_data_list)
```

```{r merge oxygen temp and salinity data with fish data}
env_dat <- left_join(big_dat_oxy, big_dat_temp, by = c("month_year", "lon", "lat")) |> 
  left_join(big_dat_sal, by = c("month_year", "lon", "lat"))
```

#### Depth

```{r depth}
# Only use unique locations and then left_join else it will take forever
# https://gis.stackexchange.com/questions/411261/read-multiple-layers-raster-from-ncdf-file-using-terra-package
# https://emodnet.ec.europa.eu/geoviewer/
dep_raster <- terra::rast(paste0(home, "/data/Mean depth natural colour (with land).nc"))

class(dep_raster)
plot(dep_raster)

env_dat$depth <- terra::extract(dep_raster, env_dat |> dplyr::select(lon, lat))$elevation

ggplot(env_dat, aes(lon, lat, color = depth*-1)) + 
  geom_point() + 
  scale_color_viridis(direction = -1)

env_dat$depth <- env_dat$depth*-1
```

#### Substrate

```{r substrate}
substrate <- terra::rast(paste0(home, "/data/substrate_tif/BALANCE_SEABED_SEDIMENT.tif"))

newcrs <- "+proj=longlat +datum=WGS84"

substrate_longlat = terra::project(substrate, newcrs)
 
plot(substrate_longlat)

# Now extract the values from the saduria raster to dat
env_dat$substrate <- terra::extract(substrate_longlat, env_dat |> dplyr::select(lon, lat))$BALANCE_SEABED_SEDIMENT

unique(env_dat$substrate)

factor(sort(unique(round(env_dat$substrate))))
 
env_dat$substrate <- round(env_dat$substrate)

env_dat <- env_dat |> mutate(substrate = ifelse(substrate == 1, "bedrock", substrate),
                             substrate = ifelse(substrate == 2, "hard-bottom complex",
                                                substrate),
                             substrate = ifelse(substrate == 3, "sand", substrate),
                             substrate = ifelse(substrate == 4, "hard clay", substrate),
                             substrate = ifelse(substrate == 5, "mud", substrate))

# I. Bedrock.
# II. Hard bottom complex, includes patchy hard surfaces and coarse sand (sometimes also clay) to boulders.
# III. Sand including fine to coarse sand (with gravel exposures).
# IV. Hard clay sometimes/often/possibly exposed or covered with a thin layer of sand/gravel.
# V. Mud including gyttja-clay to gyttja-silt.

# Plot
ggplot(env_dat, aes(lon, lat, color = substrate)) +
  geom_point()
```

```{r join}
# Now join these data with the full_dat
dat_full <- left_join(dat, env_dat, by = c("month_year", "lon", "lat"))
```

## Add UTM coords

```{r add coords}
# Add UTM coords
dat_full <- dat_full |> add_utm_columns(ll_names = c("lon", "lat"))
```

## Save data

```{r save}
dat_full_save <- dat_full |>
  dplyr::select(-IDx, -haul.id.size) |> 
  janitor::clean_names()

write_csv(dat_full_save, file = paste0(home, "/data/clean/catch_by_length.csv"))
```
